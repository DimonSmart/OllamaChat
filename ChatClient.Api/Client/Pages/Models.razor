@page "/models"
@using ChatClient.Shared.Models
@using ChatClient.Api.Services
@using System.Linq
@inject IOllamaClientService OllamaService
@inject IOpenAIClientService OpenAIService
@inject ILlmServerConfigService LlmServerConfigService

<MudContainer Class="mt-3">
    <MudText Class="page-header">Available Models</MudText>

    @if (_loading)
    {
        <MudProgressCircular Color="Color.Primary" Indeterminate="true" />
        <MudText Class="ml-2">Loading models...</MudText>
    }
    else if (_serverModels.Count == 0)
    {
        <MudAlert Severity="Severity.Info">No servers configured.</MudAlert>
    }
    else
    {
        @foreach (var server in _serverModels)
        {
            <MudText Typo="Typo.h6" Class="mt-4">@server.Server.Name</MudText>
            @if (server.ErrorMessage is not null)
            {
                <MudAlert Severity="Severity.Error" Class="mb-4">@server.ErrorMessage</MudAlert>
            }
            else if (server.Models.Count == 0)
            {
                <MudAlert Severity="Severity.Info" Class="mb-4">No models available.</MudAlert>
            }
            else
            {
                <MudAlert Severity="Severity.Info" Class="mb-3">
                    Function calling support detection is based on model metadata and naming patterns.
                    The actual capabilities may vary and should be verified through testing.
                </MudAlert>
                <MudTable Items="server.Models" Hover="true" Striped="true" Dense="true" Class="mb-4" Elevation="2">
                    <HeaderContent>
                        <MudTh>Model Name</MudTh>
                        <MudTh>Image Support</MudTh>
                        <MudTh>Function Calling</MudTh>
                        <MudTh>Modified At</MudTh>
                        <MudTh>Size</MudTh>
                    </HeaderContent>
                    <RowTemplate>
                        <MudTd DataLabel="Name">@context.Name</MudTd>
                        <MudTd DataLabel="Image Support" Style="text-align: center;">
                            @if (context.SupportsImages)
                            {
                                <span style="color: #4caf50; font-size: 20px; font-weight: bold;" title="Supports images">✓</span>
                            }
                            else
                            {
                                <span style="color: #9e9e9e; font-size: 20px;" title="Text only">−</span>
                            }
                        </MudTd>
                        <MudTd DataLabel="Function Calling" Style="text-align: center;">
                            @if (context.SupportsFunctionCalling)
                            {
                                <span style="color: #2196f3; font-size: 20px; font-weight: bold;" title="Function calling support detected (may not be accurate)">⚙</span>
                            }
                            else
                            {
                                <span style="color: #9e9e9e; font-size: 20px;" title="No function calling support detected">−</span>
                            }
                        </MudTd>
                        <MudTd DataLabel="Modified At">@FormatDate(context.ModifiedAt)</MudTd>
                        <MudTd DataLabel="Size">@FormatSize(context.Size)</MudTd>
                    </RowTemplate>
                </MudTable>
            }
        }
    }
</MudContainer>

@code {
    private List<ServerModels> _serverModels = [];
    private bool _loading = true;

    protected override async Task OnInitializedAsync()
    {
        _loading = true;
        try
        {
            var servers = await LlmServerConfigService.GetAllAsync();
            var tasks = servers.Select(async s =>
            {
                try
                {
                    var serverId = s.Id ?? Guid.Empty;
                    List<OllamaModel> models = s.ServerType == ServerType.ChatGpt
                        ? (await OpenAIService.GetAvailableModelsAsync(serverId)).Select(m => new OllamaModel { Name = m }).ToList()
                        : (await OllamaService.GetModelsAsync(serverId)).ToList();
                    return new ServerModels(s, models, null);
                }
                catch
                {
                    return new ServerModels(s, [], "This server is currently unavailable.");
                }
            });
            _serverModels = (await Task.WhenAll(tasks)).ToList();
        }
        finally
        {
            _loading = false;
        }
    }

    private string FormatDate(string timestamp)
    {
        if (DateTime.TryParse(timestamp, out var date))
            return date.ToString("g");
        return timestamp;
    }

    private string FormatSize(long bytes)
    {
        string[] sizes = { "B", "KB", "MB", "GB", "TB" };
        double len = bytes;
        var order = 0;
        while (len >= 1024 && order < sizes.Length - 1)
        {
            order++;
            len /= 1024;
        }
        return $"{len:0.##} {sizes[order]}";
    }

    private sealed record ServerModels(LlmServerConfig Server, List<OllamaModel> Models, string? ErrorMessage);
}
